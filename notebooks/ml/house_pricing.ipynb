{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initialisation de la session Spark",
   "id": "430d4c58cce318be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# spark.stop()",
   "id": "6ad450d765d88d24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"house_pricing_model\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.1\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://localhost:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    # Optimisations de performances\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .config(\"spark.executor.cores\", str(max(1, os.cpu_count() - 1)))\n",
    "    .config(\"spark.driver.memory\", \"16g\")\n",
    "    .config(\"spark.executor.memory\", \"12g\")\n",
    "    .config(\"spark.memory.fraction\", \"0.8\")\n",
    "    .config(\"spark.memory.storageFraction\", \"0.2\")\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", str(os.cpu_count() * 2))\n",
    "    .config(\"spark.default.parallelism\", str(os.cpu_count() * 2))\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    # Configuration des logs\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dlog4j.configuration=log4j.properties\")\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-Dlog4j.configuration=log4j.properties\")\n",
    "    .config(\"spark.sql.warnings.ignore\", \"true\")\n",
    "    .config(\"spark.log.level\", \"ERROR\")\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=false\")\n",
    "    .getOrCreate())"
   ],
   "id": "20e5a86db414deb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "info_df = spark.read.option(\"multiline\", \"true\").option(\"mode\", \"PERMISSIVE\").json(\"s3a://ml-datasets/house_price_model/latest/info.json\")\n",
    "version = info_df.collect()[0]['redirect_to']\n",
    "\n",
    "# Chemins des fichiers\n",
    "base_path = f\"s3a://ml-datasets/house_price_model/{version}/\""
   ],
   "id": "758ec34da77cb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chargement des données",
   "id": "34b1a7a40b8cc136"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Chargement des DataFrames\n",
    "df_full = spark.read.parquet(base_path + \"full_dataset.parquet\")\n",
    "df_train = spark.read.parquet(base_path + \"train.parquet\")\n",
    "df_validation = spark.read.parquet(base_path + \"validation.parquet\")\n",
    "df_test = spark.read.parquet(base_path + \"test.parquet\")\n",
    "\n",
    "# Affichage rapide\n",
    "df_full.printSchema()\n",
    "print(\"Nombre de lignes dans le dataset train :\", df_train.count())"
   ],
   "id": "3fb4e451e80879b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prétraitement des données",
   "id": "11c5fd30bc8588bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "def target_encoding(df, categorical_col='code_postal', target_col='valeur_fonciere', smoothing=10):\n",
    "    \"\"\"\n",
    "    Applique un target encoding sur une colonne catégorielle par rapport à la moyenne de la colonne cible.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    df : DataFrame Spark\n",
    "        Le DataFrame contenant les données\n",
    "    categorical_col : str, optionnel (défaut='code_postal')\n",
    "        Le nom de la colonne catégorielle à encoder\n",
    "    target_col : str, optionnel (défaut='valeur_fonciere')\n",
    "        Le nom de la colonne cible dont on calcule la moyenne\n",
    "    smoothing : int, optionnel (défaut=10)\n",
    "        Facteur de lissage pour éviter l'overfitting sur les catégories peu fréquentes\n",
    "\n",
    "    Return :\n",
    "    ---------\n",
    "    DataFrame : DataFrame Spark avec une nouvelle colonne contenant l'encodage\n",
    "    \"\"\"\n",
    "    # Calculer la moyenne globale de la colonne cible\n",
    "    global_avg = df.select(F.avg(target_col)).collect()[0][0]\n",
    "\n",
    "    # Calculer les statistiques par catégorie\n",
    "    category_stats = df.groupBy(categorical_col).agg(\n",
    "        F.avg(target_col).alias('category_avg'),\n",
    "        F.count('*').alias('category_count')\n",
    "    )\n",
    "\n",
    "    # Appliquer le lissage bayésien (smoothing)\n",
    "    category_stats = category_stats.withColumn(\n",
    "        'encoded_value',\n",
    "        (F.col('category_avg') * F.col('category_count') + global_avg * smoothing) /\n",
    "        (F.col('category_count') + smoothing)\n",
    "    )\n",
    "\n",
    "    # Joindre l'encodage au DataFrame original\n",
    "    encoded_col_name = f\"{categorical_col}_encoded\"\n",
    "    encoded_df = df.join(\n",
    "        category_stats.select(categorical_col, 'encoded_value'),\n",
    "        on=categorical_col,\n",
    "        how='left'\n",
    "    ).withColumnRenamed('encoded_value', encoded_col_name)\n",
    "\n",
    "    # Gérer les valeurs manquantes avec la moyenne globale\n",
    "    encoded_df = encoded_df.fillna({encoded_col_name: global_avg})\n",
    "\n",
    "    return encoded_df"
   ],
   "id": "bbba03a7100efb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "def prepare_features_with_encoding(df, target_column='valeur_fonciere',\n",
    "                                         categorical_cols=['code_postal'],\n",
    "                                         exclude_columns=None):\n",
    "    \"\"\"\n",
    "    Crée un pipeline de prétraitement avec target encoding pour les colonnes catégorielles.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    df : DataFrame Spark\n",
    "        Le DataFrame d'entraînement contenant les données\n",
    "    target_column : str, optionnel (défaut='valeur_fonciere')\n",
    "        Le nom de la colonne cible à prédire\n",
    "    categorical_cols : list, optionnel (défaut=['code_postal'])\n",
    "        Liste des colonnes catégorielles à encoder\n",
    "    exclude_columns : list, optionnel\n",
    "        Liste des colonnes à exclure du vecteur de caractéristiques\n",
    "\n",
    "    Retourne:\n",
    "    ---------\n",
    "    Tuple : (DataFrame transformé, PipelineModel de prétraitement)\n",
    "    \"\"\"\n",
    "    # Initialiser la liste d'exclusion\n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = []\n",
    "\n",
    "    # Ajouter la colonne cible à la liste d'exclusion\n",
    "    if target_column not in exclude_columns:\n",
    "        exclude_columns.append(target_column)\n",
    "\n",
    "    # Étapes du pipeline\n",
    "    stages = []\n",
    "\n",
    "    # Créer les transformations pour chaque colonne catégorielle\n",
    "    # for cat_col in categorical_cols:\n",
    "    #     # Calculer la moyenne globale et les statistiques par catégorie en utilisant SQLTransformer\n",
    "    #     encoded_col = f\"{cat_col}_encoded\"\n",
    "    #\n",
    "    #     # Étape 1: Calculer les statistiques globales et par catégorie\n",
    "    #     stats_calculator = SQLTransformer(\n",
    "    #         statement=f\"\"\"\n",
    "    #         WITH global_stats AS (\n",
    "    #             SELECT AVG({target_column}) as global_avg FROM __THIS__\n",
    "    #         ),\n",
    "    #         category_stats AS (\n",
    "    #             SELECT\n",
    "    #                 {cat_col},\n",
    "    #                 AVG({target_column}) as category_avg,\n",
    "    #                 COUNT(*) as category_count\n",
    "    #             FROM __THIS__\n",
    "    #             GROUP BY {cat_col}\n",
    "    #         )\n",
    "    #         SELECT\n",
    "    #             t.*,\n",
    "    #             COALESCE(\n",
    "    #                 (cs.category_avg * cs.category_count + gs.global_avg * 10) / (cs.category_count + 10),\n",
    "    #                 gs.global_avg\n",
    "    #             ) as {encoded_col}\n",
    "    #         FROM __THIS__ t\n",
    "    #         CROSS JOIN global_stats gs\n",
    "    #         LEFT JOIN category_stats cs ON t.{cat_col} = cs.{cat_col}\n",
    "    #         \"\"\"\n",
    "    #     )\n",
    "    #     stages.append(stats_calculator)\n",
    "\n",
    "    # Identifier les colonnes numériques\n",
    "    numeric_columns = [col for col, dtype in df.dtypes\n",
    "                      if dtype in ['int', 'double', 'float']\n",
    "                      and col not in exclude_columns]\n",
    "\n",
    "    # Ajouter les colonnes encodées\n",
    "    # encoded_columns = [f\"{col}_encoded\" for col in categorical_cols]\n",
    "\n",
    "    # Toutes les colonnes à utiliser comme features\n",
    "    # feature_columns = numeric_columns + encoded_columns\n",
    "    feature_columns = numeric_columns\n",
    "    print(f\"Colonnes utilisées comme caractéristiques: {feature_columns}\")\n",
    "\n",
    "    # Ajouter l'étape d'assemblage des vecteurs\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=feature_columns,\n",
    "        outputCol=\"features\",\n",
    "        handleInvalid=\"skip\"\n",
    "    )\n",
    "    stages.append(assembler)\n",
    "\n",
    "    # Créer et appliquer le pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    pipeline_model = pipeline.fit(df)\n",
    "\n",
    "    # Transformer le DataFrame d'entraînement\n",
    "    df_transformed = pipeline_model.transform(df).select(\"features\", target_column)\n",
    "\n",
    "    return df_transformed, pipeline_model"
   ],
   "id": "23b0665c6b103138",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "preprocessing_model = prepare_features_with_encoding(df_train)[1]\n",
    "\n",
    "df_train_features = preprocessing_model.transform(df_train).select(\"features\", \"valeur_fonciere\")\n",
    "df_validation_features = preprocessing_model.transform(df_validation).select(\"features\", \"valeur_fonciere\")\n",
    "df_test_features = preprocessing_model.transform(df_test).select(\"features\", \"valeur_fonciere\")"
   ],
   "id": "f0440fd4425bcac5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Création Baseline",
   "id": "fbf96811a22030cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "f1f6f5bae2a72191",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_baselines_from_raw_df(df_train, df_validation, df_test, target_column=\"valeur_fonciere\"):\n",
    "    \"\"\"\n",
    "    Crée plusieurs modèles baseline directement à partir des données brutes (non vectorisées)\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    df_train : DataFrame Spark\n",
    "        DataFrame d'entraînement brut avec toutes les colonnes originales\n",
    "    df_validation : DataFrame Spark\n",
    "        DataFrame de validation brut avec toutes les colonnes originales\n",
    "    df_test : DataFrame Spark\n",
    "        DataFrame de test brut avec toutes les colonnes originales\n",
    "    target_column : str\n",
    "        Nom de la colonne cible à prédire\n",
    "\n",
    "    Retourne:\n",
    "    ---------\n",
    "    dict : Dictionnaire des performances des différents modèles baseline\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Vérifier que les colonnes nécessaires existent\n",
    "    required_cols = [\"surface_reelle_bati\", \"code_postal\", target_column, \"nombre_pieces_principales\"]\n",
    "    for col in required_cols:\n",
    "        if col not in df_train.columns:\n",
    "            raise ValueError(f\"La colonne '{col}' est requise mais n'est pas présente dans le DataFrame\")\n",
    "\n",
    "    print(\"Schéma du DataFrame d'entraînement:\")\n",
    "    df_train.printSchema()\n",
    "\n",
    "    # 1. Baseline #1: Moyenne globale\n",
    "    global_mean = df_train.select(F.mean(target_column).alias(\"prediction\")).collect()[0][0]\n",
    "    print(f\"Moyenne globale des prix: {global_mean:.2f}\")\n",
    "\n",
    "    # Prédiction avec la moyenne globale\n",
    "    global_mean_predictions = df_validation.withColumn(\"prediction\", F.lit(global_mean))\n",
    "\n",
    "    # Évaluation\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=target_column,\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"rmse\"\n",
    "    )\n",
    "\n",
    "    rmse = evaluator.evaluate(global_mean_predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(global_mean_predictions)\n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(global_mean_predictions)\n",
    "\n",
    "    results[\"moyenne_globale\"] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2\n",
    "    }\n",
    "\n",
    "    print(f\"Baseline Moyenne Globale: RMSE = {rmse:.2f}, MAE = {mae:.2f}, R² = {r2:.4f}\")\n",
    "\n",
    "    # 2. Baseline #2: Moyenne par code postal\n",
    "    print(\"Calcul de la baseline par code postal...\")\n",
    "    postal_code_means = df_train.groupBy(\"code_postal\").agg(\n",
    "        F.mean(target_column).alias(\"postal_mean\"),\n",
    "        F.count(\"*\").alias(\"count\")\n",
    "    )\n",
    "\n",
    "    # Nombre de codes postaux uniques\n",
    "    num_postal_codes = postal_code_means.count()\n",
    "    print(f\"Nombre de codes postaux uniques: {num_postal_codes}\")\n",
    "\n",
    "    # Joindre avec le dataset de validation\n",
    "    postal_predictions = df_validation.join(\n",
    "        postal_code_means,\n",
    "        on=\"code_postal\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Utiliser la moyenne globale pour les codes postaux non présents dans l'ensemble d'entraînement\n",
    "    postal_predictions = postal_predictions.withColumn(\n",
    "        \"prediction\",\n",
    "        F.coalesce(F.col(\"postal_mean\"), F.lit(global_mean))\n",
    "    )\n",
    "\n",
    "    # Évaluation\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(postal_predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(postal_predictions)\n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(postal_predictions)\n",
    "\n",
    "    results[\"moyenne_code_postal\"] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2\n",
    "    }\n",
    "\n",
    "    print(f\"Baseline Moyenne par Code Postal: RMSE = {rmse:.2f}, MAE = {mae:.2f}, R² = {r2:.4f}\")\n",
    "\n",
    "    # 3. Baseline #3: Régression linéaire sur la surface uniquement\n",
    "    # Créer un vecteur avec une seule caractéristique\n",
    "    surface_assembler = VectorAssembler(\n",
    "        inputCols=[\"surface_reelle_bati\"],\n",
    "        outputCol=\"surface_feature\",\n",
    "        handleInvalid=\"skip\"\n",
    "    )\n",
    "\n",
    "    train_surface = surface_assembler.transform(df_train)\n",
    "    validation_surface = surface_assembler.transform(df_validation)\n",
    "\n",
    "    # Entraîner une régression linéaire simple\n",
    "    lr_surface = LinearRegression(\n",
    "        featuresCol=\"surface_feature\",\n",
    "        labelCol=target_column,\n",
    "        maxIter=10,\n",
    "        regParam=0.0,\n",
    "        elasticNetParam=0.0\n",
    "    )\n",
    "\n",
    "    lr_surface_model = lr_surface.fit(train_surface)\n",
    "    validation_predictions = lr_surface_model.transform(validation_surface)\n",
    "\n",
    "    # Évaluation\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(validation_predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(validation_predictions)\n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(validation_predictions)\n",
    "\n",
    "    results[\"regression_surface\"] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2,\n",
    "        \"coefficients\": lr_surface_model.coefficients.toArray().tolist(),\n",
    "        \"intercept\": lr_surface_model.intercept\n",
    "    }\n",
    "\n",
    "    print(f\"Baseline Régression Surface: RMSE = {rmse:.2f}, MAE = {mae:.2f}, R² = {r2:.4f}\")\n",
    "    print(f\"Équation: prix = {lr_surface_model.intercept:.2f} + {lr_surface_model.coefficients[0]:.2f} × surface\")\n",
    "\n",
    "    # 4. Baseline #4: Régression linéaire sur le nombre de pièces uniquement\n",
    "    pieces_assembler = VectorAssembler(\n",
    "        inputCols=[\"nombre_pieces_principales\"],\n",
    "        outputCol=\"pieces_feature\",\n",
    "        handleInvalid=\"skip\"\n",
    "    )\n",
    "\n",
    "    train_pieces = pieces_assembler.transform(df_train)\n",
    "    validation_pieces = pieces_assembler.transform(df_validation)\n",
    "\n",
    "    # Entraîner une régression linéaire simple\n",
    "    lr_pieces = LinearRegression(\n",
    "        featuresCol=\"pieces_feature\",\n",
    "        labelCol=target_column,\n",
    "        maxIter=10,\n",
    "        regParam=0.0,\n",
    "        elasticNetParam=0.0\n",
    "    )\n",
    "\n",
    "    lr_pieces_model = lr_pieces.fit(train_pieces)\n",
    "    validation_predictions = lr_pieces_model.transform(validation_pieces)\n",
    "\n",
    "    # Évaluation\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(validation_predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(validation_predictions)\n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(validation_predictions)\n",
    "\n",
    "    results[\"regression_pieces\"] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2,\n",
    "        \"coefficients\": lr_pieces_model.coefficients.toArray().tolist(),\n",
    "        \"intercept\": lr_pieces_model.intercept\n",
    "    }\n",
    "\n",
    "    print(f\"Baseline Régression Nombre de Pièces: RMSE = {rmse:.2f}, MAE = {mae:.2f}, R² = {r2:.4f}\")\n",
    "    print(f\"Équation: prix = {lr_pieces_model.intercept:.2f} + {lr_pieces_model.coefficients[0]:.2f} × nombre_pieces\")\n",
    "\n",
    "    # 5. Baseline #5: Régression linéaire sur surface et nombre de pièces\n",
    "    multi_assembler = VectorAssembler(\n",
    "        inputCols=[\"surface_reelle_bati\", \"nombre_pieces_principales\"],\n",
    "        outputCol=\"multi_features\",\n",
    "        handleInvalid=\"skip\"\n",
    "    )\n",
    "\n",
    "    train_multi = multi_assembler.transform(df_train)\n",
    "    validation_multi = multi_assembler.transform(df_validation)\n",
    "\n",
    "    # Entraîner une régression linéaire multi-features\n",
    "    lr_multi = LinearRegression(\n",
    "        featuresCol=\"multi_features\",\n",
    "        labelCol=target_column,\n",
    "        maxIter=10,\n",
    "        regParam=0.0,\n",
    "        elasticNetParam=0.0\n",
    "    )\n",
    "\n",
    "    lr_multi_model = lr_multi.fit(train_multi)\n",
    "    validation_predictions = lr_multi_model.transform(validation_multi)\n",
    "\n",
    "    # Évaluation\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(validation_predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(validation_predictions)\n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(validation_predictions)\n",
    "\n",
    "    results[\"regression_surface_pieces\"] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2,\n",
    "        \"coefficients\": lr_multi_model.coefficients.toArray().tolist(),\n",
    "        \"intercept\": lr_multi_model.intercept\n",
    "    }\n",
    "\n",
    "    print(f\"Baseline Régression Surface + Pièces: RMSE = {rmse:.2f}, MAE = {mae:.2f}, R² = {r2:.4f}\")\n",
    "    print(f\"Équation: prix = {lr_multi_model.intercept:.2f} + {lr_multi_model.coefficients[0]:.2f} × surface + {lr_multi_model.coefficients[1]:.2f} × pièces\")\n",
    "\n",
    "    # 6. Baseline #6: Régression linéaire sur toutes les features numériques\n",
    "    # Identifier les colonnes numériques (hors target)\n",
    "    numeric_cols = [col for col, dtype in df_train.dtypes\n",
    "                  if dtype in ['int', 'double', 'float']\n",
    "                  and col != target_column]\n",
    "\n",
    "    print(f\"Colonnes numériques utilisées pour la régression linéaire: {numeric_cols}\")\n",
    "\n",
    "    # Assembler toutes les features numériques\n",
    "    all_features_assembler = VectorAssembler(\n",
    "        inputCols=numeric_cols,\n",
    "        outputCol=\"features\",\n",
    "        handleInvalid=\"skip\"\n",
    "    )\n",
    "\n",
    "    train_all_features = all_features_assembler.transform(df_train)\n",
    "    validation_all_features = all_features_assembler.transform(df_validation)\n",
    "\n",
    "    # Entraîner une régression linéaire sur toutes les features\n",
    "    lr_all = LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=target_column,\n",
    "        maxIter=10,\n",
    "        regParam=0.01,\n",
    "        elasticNetParam=0.0\n",
    "    )\n",
    "\n",
    "    lr_all_model = lr_all.fit(train_all_features)\n",
    "    validation_predictions = lr_all_model.transform(validation_all_features)\n",
    "\n",
    "    # Évaluation\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(validation_predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(validation_predictions)\n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(validation_predictions)\n",
    "\n",
    "    results[\"regression_lineaire\"] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2,\n",
    "        \"coefficients\": lr_all_model.coefficients.toArray().tolist(),\n",
    "        \"intercept\": lr_all_model.intercept\n",
    "    }\n",
    "\n",
    "    print(f\"Baseline Régression Linéaire (toutes features): RMSE = {rmse:.2f}, MAE = {mae:.2f}, R² = {r2:.4f}\")\n",
    "\n",
    "    # 7. Baseline #7: Arbre de décision simple (profondeur limitée)\n",
    "    dt = DecisionTreeRegressor(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=target_column,\n",
    "        maxDepth=3  # Profondeur très limitée pour éviter l'overfitting\n",
    "    )\n",
    "\n",
    "    dt_model = dt.fit(train_all_features)\n",
    "    validation_predictions = dt_model.transform(validation_all_features)\n",
    "\n",
    "    # Évaluation\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(validation_predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(validation_predictions)\n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(validation_predictions)\n",
    "\n",
    "    results[\"arbre_decision_simple\"] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2\n",
    "    }\n",
    "\n",
    "    print(f\"Baseline Arbre de Décision Simple: RMSE = {rmse:.2f}, MAE = {mae:.2f}, R² = {r2:.4f}\")\n",
    "\n",
    "    # 8. Baseline #8: Régression linéaire avec transformation logarithmique\n",
    "    # Filtrer les valeurs négatives ou nulles (qui causeraient des problèmes avec log)\n",
    "    train_log_filtered = df_train.filter(F.col(target_column) > 0)\n",
    "    validation_log_filtered = df_validation.filter(F.col(target_column) > 0)\n",
    "\n",
    "    # Appliquer la transformation log\n",
    "    train_log = all_features_assembler.transform(\n",
    "        train_log_filtered.withColumn(\"log_target\", F.log1p(F.col(target_column)))\n",
    "    )\n",
    "    validation_log = all_features_assembler.transform(\n",
    "        validation_log_filtered.withColumn(\"log_target\", F.log1p(F.col(target_column)))\n",
    "    )\n",
    "\n",
    "    # Entraîner une régression linéaire sur le log des prix\n",
    "    lr_log = LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"log_target\",\n",
    "        maxIter=10,\n",
    "        regParam=0.01,\n",
    "        elasticNetParam=0.0\n",
    "    )\n",
    "\n",
    "    lr_log_model = lr_log.fit(train_log)\n",
    "    validation_log_pred = lr_log_model.transform(validation_log)\n",
    "\n",
    "    # Convertir les prédictions pour les ramener à l'échelle originale\n",
    "    validation_pred = validation_log_pred.withColumn(\n",
    "        \"prediction\",\n",
    "        F.expm1(F.col(\"prediction\"))\n",
    "    ).select(\"prediction\", target_column)\n",
    "\n",
    "    # Évaluation\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(validation_pred)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(validation_pred)\n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(validation_pred)\n",
    "\n",
    "    results[\"regression_log_transformee\"] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2,\n",
    "        \"coefficients\": lr_log_model.coefficients.toArray().tolist(),\n",
    "        \"intercept\": lr_log_model.intercept\n",
    "    }\n",
    "\n",
    "    print(f\"Baseline Régression Log-transformée: RMSE = {rmse:.2f}, MAE = {mae:.2f}, R² = {r2:.4f}\")\n",
    "\n",
    "    # 9. Baseline #9: Prix au m² moyen (global) × surface\n",
    "    # Calculer le prix moyen au m²\n",
    "    price_per_sqm = df_train.filter(F.col(\"surface_reelle_bati\") > 0).withColumn(\n",
    "        \"price_per_sqm\", F.col(target_column) / F.col(\"surface_reelle_bati\")\n",
    "    ).select(F.mean(\"price_per_sqm\")).collect()[0][0]\n",
    "\n",
    "    print(f\"Prix moyen au m²: {price_per_sqm:.2f}€\")\n",
    "\n",
    "    # Appliquer ce prix moyen aux surfaces du jeu de validation\n",
    "    ppm_predictions = df_validation.withColumn(\n",
    "        \"prediction\", F.col(\"surface_reelle_bati\") * F.lit(price_per_sqm)\n",
    "    )\n",
    "\n",
    "    # Évaluation\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(ppm_predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(ppm_predictions)\n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(ppm_predictions)\n",
    "\n",
    "    results[\"prix_m2_moyen\"] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2,\n",
    "        \"price_per_sqm\": price_per_sqm\n",
    "    }\n",
    "\n",
    "    print(f\"Baseline Prix au m² moyen: RMSE = {rmse:.2f}, MAE = {mae:.2f}, R² = {r2:.4f}\")\n",
    "    print(f\"Équation: prix = {price_per_sqm:.2f} × surface\")\n",
    "\n",
    "    # 10. Baseline #10: Prix au m² par code postal × surface\n",
    "    # Calculer le prix moyen au m² par code postal\n",
    "    price_per_sqm_by_postal = df_train.filter(F.col(\"surface_reelle_bati\") > 0).withColumn(\n",
    "        \"price_per_sqm\", F.col(target_column) / F.col(\"surface_reelle_bati\")\n",
    "    ).groupBy(\"code_postal\").agg(\n",
    "        F.mean(\"price_per_sqm\").alias(\"postal_ppm\"),\n",
    "        F.count(\"*\").alias(\"count\")\n",
    "    )\n",
    "\n",
    "    # Calculer également la moyenne globale pour les codes postaux manquants\n",
    "\n",
    "    # Joindre avec le jeu de validation\n",
    "    ppm_postal_predictions = df_validation.join(\n",
    "        price_per_sqm_by_postal,\n",
    "        on=\"code_postal\",\n",
    "        how=\"left\"\n",
    "    ).withColumn(\n",
    "        \"postal_ppm\",\n",
    "        F.coalesce(F.col(\"postal_ppm\"), F.lit(price_per_sqm))\n",
    "    ).withColumn(\n",
    "        \"prediction\",\n",
    "        F.col(\"surface_reelle_bati\") * F.col(\"postal_ppm\")\n",
    "    )\n",
    "\n",
    "    # Évaluation\n",
    "    rmse = evaluator.setMetricName(\"rmse\").evaluate(ppm_postal_predictions)\n",
    "    mae = evaluator.setMetricName(\"mae\").evaluate(ppm_postal_predictions)\n",
    "    r2 = evaluator.setMetricName(\"r2\").evaluate(ppm_postal_predictions)\n",
    "\n",
    "    results[\"prix_m2_par_code_postal\"] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2\n",
    "    }\n",
    "\n",
    "    print(f\"Baseline Prix au m² par code postal: RMSE = {rmse:.2f}, MAE = {mae:.2f}, R² = {r2:.4f}\")\n",
    "\n",
    "    # Résumé des performances\n",
    "    print(\"\\nRésumé des performances des modèles baseline:\")\n",
    "    for model, metrics in results.items():\n",
    "        print(f\"{model}: RMSE = {metrics['rmse']:.2f}, R² = {metrics['r2']:.4f}\")\n",
    "\n",
    "    return results"
   ],
   "id": "18d23a0973087513",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def visualize_baseline_results(results):\n",
    "    \"\"\"\n",
    "    Visualise les performances des différents modèles baseline\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Dictionnaire des performances des différents modèles\n",
    "    \"\"\"\n",
    "    # Extraction des métriques pour chaque modèle\n",
    "    models = list(results.keys())\n",
    "    rmse_values = [results[model][\"rmse\"] for model in models]\n",
    "    r2_values = [results[model][\"r2\"] for model in models]\n",
    "\n",
    "    # Création d'un dataframe pour faciliter la visualisation\n",
    "    performance_df = pd.DataFrame({\n",
    "        \"Modèle\": models,\n",
    "        \"RMSE\": rmse_values,\n",
    "        \"R²\": r2_values\n",
    "    })\n",
    "\n",
    "    # Trier par RMSE croissant (meilleure performance)\n",
    "    performance_df = performance_df.sort_values(\"RMSE\")\n",
    "\n",
    "    # Visualisation des RMSE\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    bars = plt.barh(performance_df[\"Modèle\"], performance_df[\"RMSE\"], color=\"skyblue\")\n",
    "    plt.xlabel(\"RMSE (€)\")\n",
    "    plt.title(\"Comparaison des modèles baseline - RMSE\")\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(bar.get_width() + 5000, bar.get_y() + bar.get_height()/2,\n",
    "                f'{performance_df[\"RMSE\"].iloc[i]:.0f}€',\n",
    "                va='center', fontsize=9)\n",
    "\n",
    "    # Visualisation des R²\n",
    "    plt.subplot(2, 1, 2)\n",
    "    bars = plt.barh(performance_df[\"Modèle\"], performance_df[\"R²\"], color=\"lightgreen\")\n",
    "    plt.xlabel(\"R²\")\n",
    "    plt.title(\"Comparaison des modèles baseline - R²\")\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "                f'{performance_df[\"R²\"].iloc[i]:.4f}',\n",
    "                va='center', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"baseline_models_comparison.png\")\n",
    "    plt.show()\n",
    "\n",
    "    return performance_df"
   ],
   "id": "9fe99dcabea10f90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_linear_coefficients(results, feature_names=None):\n",
    "    \"\"\"\n",
    "    Analyse les coefficients des modèles de régression linéaire\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Dictionnaire des performances avec les coefficients\n",
    "    feature_names : list, optionnel\n",
    "        Noms des features (pour la régression linéaire)\n",
    "    \"\"\"\n",
    "    # Modèles de régression à analyser\n",
    "    regression_models = {}\n",
    "\n",
    "    # Extraire les modèles avec des coefficients\n",
    "    for model_name, metrics in results.items():\n",
    "        if \"coefficients\" in metrics and \"intercept\" in metrics:\n",
    "            regression_models[model_name] = {\n",
    "                \"coefficients\": metrics[\"coefficients\"],\n",
    "                \"intercept\": metrics[\"intercept\"]\n",
    "            }\n",
    "\n",
    "    if not regression_models:\n",
    "        print(\"Aucun modèle de régression avec coefficients trouvé.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nAnalyse des coefficients des modèles de régression:\")\n",
    "\n",
    "    for model_name, model_info in regression_models.items():\n",
    "        print(f\"\\nModèle: {model_name}\")\n",
    "        print(f\"Intercept: {model_info['intercept']:.2f}\")\n",
    "\n",
    "        coefs = model_info[\"coefficients\"]\n",
    "\n",
    "        if feature_names and len(coefs) == len(feature_names):\n",
    "            for i, (coef, name) in enumerate(zip(coefs, feature_names)):\n",
    "                print(f\"  {name}: {coef:.2f}\")\n",
    "\n",
    "            # Visualisation des coefficients\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            bars = plt.barh(feature_names, coefs, color=\"lightblue\")\n",
    "            plt.axvline(0, color='gray', linestyle='--')\n",
    "            plt.title(f\"Coefficients du modèle {model_name}\")\n",
    "            plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "            # Ajouter les valeurs sur les barres\n",
    "            for i, bar in enumerate(bars):\n",
    "                plt.text(bar.get_width() + (0.01 if bar.get_width() >= 0 else -0.01),\n",
    "                        bar.get_y() + bar.get_height()/2,\n",
    "                        f'{coefs[i]:.2f}',\n",
    "                        va='center', ha='left' if bar.get_width() >= 0 else 'right',\n",
    "                        fontsize=9)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{model_name}_coefficients.png\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"  Coefficients: {coefs}\")"
   ],
   "id": "dc7e9c95924789d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Créer et évaluer les baselines à partir des données brutes\n",
    "baseline_results = create_baselines_from_raw_df(\n",
    "    df_train,              # DataFrame original avec toutes les colonnes\n",
    "    df_validation,\n",
    "    df_test,\n",
    "    target_column=\"valeur_fonciere\"\n",
    ")\n",
    "\n",
    "# 2. Visualiser les résultats\n",
    "performance_df = visualize_baseline_results(baseline_results)\n",
    "\n",
    "# 3. Analyser les coefficients des modèles linéaires\n",
    "numeric_cols = [col for col, dtype in df_train.dtypes\n",
    "              if dtype in ['int', 'double', 'float']\n",
    "              and col != \"valeur_fonciere\"]\n",
    "analyze_linear_coefficients(baseline_results, feature_names=numeric_cols)"
   ],
   "id": "e82b2110c71ad1d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observations clés\n",
    "\n",
    "La localisation est cruciale:\n",
    "- Le modèle \"Prix au m² par code postal\" est le plus performant, expliquant 33.7% de la variance des prix. Cela confirme l'importance de la localisation dans la valorisation immobilière.\n",
    "- La surface est plus explicative que le nombre de pièces: La régression basée uniquement sur la surface (R² = 0.1850) est bien meilleure que celle basée sur le nombre de pièces (R² = 0.0941).\n",
    "- Interaction surface/pièces peu significative: La combinaison de surface et pièces (R² = 0.1858) n'améliore que très légèrement la performance par rapport à la surface seule, et on note même un coefficient négatif pour les pièces (-3,572€) lorsque la surface est déjà prise en compte.\n",
    "- Transformations log peu efficaces: La régression logarithmique ne semble pas améliorer les performances, ce qui suggère que malgré une probable asymétrie, la relation prix/variables reste assez linéaire.\n",
    "- Effet des autres variables numériques: La régression linéaire utilisant toutes les features numériques (R² = 0.2534) est nettement meilleure que celle utilisant uniquement la surface, ce qui montre l'importance des autres facteurs comme l'année, le terrain, et les coordonnées géographiques.\n",
    "\n",
    "### Analyse des coefficients de la régression linéaire complète\n",
    "\n",
    "- code_type_local: +150,170€ par unité, suggérant une forte influence du type de bien\n",
    "- latitude: -55,164€ par degré, indiquant que les prix diminuent en allant vers le nord dans votre dataset\n",
    "- annee_mutation: +17,872€ par année, ce qui montre une inflation immobilière significative\n",
    "- longitude: +6,219€ par degré, montrant un gradient est-ouest des prix\n",
    "- nombre_pieces_principales: +3,050€ par pièce (après contrôle des autres variables)\n",
    "- surface_reelle_bati: +1,950€ par m² (en contrôlant pour les autres variables)\n",
    "- ratio_terrain_bati: +194€ par unité, impact positif mais modéré\n",
    "- surface_terrain: +0.98€ par m², impact très faible par rapport à la surface bâtie"
   ],
   "id": "288ea958b7ccde53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Entraînement du modèle GBTRegressor",
   "id": "45a847436b7d3784"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "def train_gradient_boosting(train_df, val_df, target_column='valeur_fonciere'):\n",
    "    \"\"\"\n",
    "    Entraîne un modèle GBT en optimisant l'utilisation des ressources disponibles\n",
    "\n",
    "    Args:\n",
    "        train_df (pyspark.sql.DataFrame): DataFrame d'entraînement\n",
    "        val_df (pyspark.sql.DataFrame): DataFrame de validation\n",
    "        target_column (str): Nom de la colonne cible\n",
    "\n",
    "    Returns :\n",
    "        tuple : Modèle entraîné et métriques de performance\n",
    "    \"\"\"\n",
    "\n",
    "    # Mettre en cache les DataFrames\n",
    "    train_df.cache()\n",
    "    val_df.cache()\n",
    "\n",
    "    # Forcer une action pour matérialiser les caches\n",
    "    train_count = train_df.count()\n",
    "    val_count = val_df.count()\n",
    "    print(f\"Train set: {train_count} rows, Validation set: {val_count} rows\")\n",
    "\n",
    "    # Définir une grille de paramètres à tester\n",
    "    gbt = GBTRegressor(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=target_column,\n",
    "        predictionCol=\"predicted_\" + target_column\n",
    "    )\n",
    "\n",
    "    param_grid = ParamGridBuilder() \\\n",
    "        .addGrid(gbt.maxDepth, [8]) \\\n",
    "        .addGrid(gbt.maxIter, [30, 40]) \\\n",
    "        .addGrid(gbt.stepSize, [0.07, 0.08]) \\\n",
    "        .addGrid(gbt.subsamplingRate, [0.8, 0.9]) \\\n",
    "        .build()\n",
    "\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=target_column,\n",
    "        predictionCol=\"predicted_\" + target_column,\n",
    "        metricName=\"rmse\"\n",
    "    )\n",
    "\n",
    "    cv = CrossValidator(\n",
    "        estimator=gbt,\n",
    "        estimatorParamMaps=param_grid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=2,\n",
    "        parallelism=14,\n",
    "    )\n",
    "\n",
    "    print(f\"Début de la recherche d'hyperparamètres...\")\n",
    "    cv_model = cv.fit(train_df)\n",
    "    best_model = cv_model.bestModel\n",
    "    print(\"Recherche terminée\")\n",
    "\n",
    "    # Extraire les meilleurs hyperparamètres\n",
    "    best_params = {}\n",
    "    if hasattr(cv_model, 'getEstimatorParamMaps'):\n",
    "        # Récupérer l'index du meilleur modèle\n",
    "        best_index = np.argmin(cv_model.avgMetrics)\n",
    "        # Récupérer les paramètres correspondants\n",
    "        best_params = {str(k): v for k, v in cv_model.getEstimatorParamMaps()[best_index].items()}\n",
    "    else:\n",
    "        # Essayer de récupérer directement les paramètres du meilleur modèle\n",
    "        try:\n",
    "            best_params = {\n",
    "                \"maxDepth\": cv_model.bestModel.getMaxDepth(),\n",
    "                \"maxIter\": cv_model.bestModel.getMaxIter(),\n",
    "                \"stepSize\": cv_model.bestModel.getStepSize(),\n",
    "                \"subsamplingRate\": cv_model.bestModel.getSubsamplingRate()\n",
    "            }\n",
    "        except:\n",
    "            print(\"Impossible de récupérer les paramètres du meilleur modèle\")\n",
    "\n",
    "    # Générer des prédictions\n",
    "    print(\"Génération des prédictions...\")\n",
    "    predictions = best_model.transform(val_df).select(\n",
    "        target_column,\n",
    "        \"predicted_\" + target_column\n",
    "    )\n",
    "\n",
    "    # Évaluation du modèle\n",
    "    print(\"Évaluation du modèle...\")\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=target_column,\n",
    "        predictionCol=\"predicted_\" + target_column\n",
    "    )\n",
    "\n",
    "    # Calculer les métriques\n",
    "    metrics = {}\n",
    "    for metric_name in [\"rmse\", \"mae\", \"r2\"]:\n",
    "        evaluator.setMetricName(metric_name)\n",
    "        metrics[metric_name] = evaluator.evaluate(predictions)\n",
    "\n",
    "    # Calculer le pourcentage d'erreur\n",
    "    predictions_with_error = predictions.withColumn(\n",
    "        \"percent_error\",\n",
    "        F.abs(F.col(\"predicted_\" + target_column) - F.col(target_column)) / F.col(target_column) * 100\n",
    "    )\n",
    "\n",
    "    error_stats = predictions_with_error.select(\n",
    "        F.avg(\"percent_error\").alias(\"avg_percent_error\"),\n",
    "        F.expr(\"percentile(percent_error, 0.5)\").alias(\"median_percent_error\")\n",
    "    ).collect()[0]\n",
    "\n",
    "    metrics[\"avg_percent_error\"] = error_stats[\"avg_percent_error\"]\n",
    "    metrics[\"median_percent_error\"] = error_stats[\"median_percent_error\"]\n",
    "\n",
    "    # Ajouter les informations du modèle\n",
    "    try:\n",
    "        # Pour les modèles GBT de PySpark\n",
    "        metrics[\"num_trees\"] = best_model.trees\n",
    "    except:\n",
    "        try:\n",
    "            # Autre méthode alternative\n",
    "            metrics[\"num_trees\"] = best_model.getNumTrees()\n",
    "        except:\n",
    "            metrics[\"num_trees\"] = None\n",
    "\n",
    "    # Tentative de récupération des importances des features\n",
    "    try:\n",
    "        metrics[\"feature_importances\"] = best_model.featureImportances.toArray().tolist()\n",
    "    except:\n",
    "        metrics[\"feature_importances\"] = None\n",
    "\n",
    "    metrics[\"best_params\"] = best_params\n",
    "\n",
    "    # Libérer les caches\n",
    "    train_df.unpersist()\n",
    "    val_df.unpersist()\n",
    "\n",
    "    # Afficher un résumé\n",
    "    print(f\"Performances du modèle: RMSE={metrics['rmse']:.2f}, MAE={metrics['mae']:.2f}, R²={metrics['r2']:.4f}\")\n",
    "    print(f\"Erreur moyenne: {metrics['avg_percent_error']:.2f}%, Erreur médiane: {metrics['median_percent_error']:.2f}%\")\n",
    "\n",
    "    return best_model, metrics"
   ],
   "id": "16b8a0000529d196",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Entraîner le modèle Gradient Boosting\n",
    "model, metrics = train_gradient_boosting(    df_train_features,\n",
    "    df_validation_features,\n",
    "    target_column='valeur_fonciere')"
   ],
   "id": "9a72b96fa83b45f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Appliquer le modèle sur les données de test\n",
    "predictions_test = model.transform(df_test_features)\n",
    "\n",
    "# Créer un évaluateur\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"valeur_fonciere\",\n",
    "    predictionCol=\"predicted_valeur_fonciere\"\n",
    ")\n",
    "\n",
    "# Calculer les métriques sur le jeu de test\n",
    "test_metrics = {}\n",
    "for metric_name in [\"rmse\", \"mae\", \"r2\"]:\n",
    "    evaluator.setMetricName(metric_name)\n",
    "    test_metrics[metric_name] = evaluator.evaluate(predictions_test)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"\\nPerformances sur le jeu de test:\")\n",
    "print(f\"RMSE: {test_metrics['rmse']:.2f}\")\n",
    "print(f\"MAE: {test_metrics['mae']:.2f}\")\n",
    "print(f\"R²: {test_metrics['r2']:.4f}\")\n",
    "\n",
    "# Pour comparer avec les performances sur le jeu de validation\n",
    "print(\"\\nComparaison validation vs test:\")\n",
    "print(f\"RMSE - Validation: {metrics['rmse']:.2f}, Test: {test_metrics['rmse']:.2f}\")\n",
    "print(f\"R² - Validation: {metrics['r2']:.4f}, Test: {test_metrics['r2']:.4f}\")\n",
    "\n",
    "price_comparison = predictions_test.select(\n",
    "    \"valeur_fonciere\",\n",
    "    \"predicted_valeur_fonciere\",\n",
    "    (F.col(\"predicted_valeur_fonciere\") - F.col(\"valeur_fonciere\")).alias(\"error\"),\n",
    "    F.abs(F.col(\"predicted_valeur_fonciere\") - F.col(\"valeur_fonciere\")).alias(\"absolute_error\"),\n",
    "    (F.abs(F.col(\"predicted_valeur_fonciere\") - F.col(\"valeur_fonciere\")) / F.col(\"valeur_fonciere\") * 100).alias(\"percent_error\")\n",
    ")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "print(\"\\nExemples de prédictions:\")\n",
    "price_comparison.orderBy(F.rand()).limit(10).show(truncate=False)\n",
    "\n",
    "# Calcul des statistiques d'erreur avec erreur absolue\n",
    "print(\"\\nStatistiques d'erreur:\")\n",
    "price_comparison.select(\n",
    "    F.avg(\"absolute_error\").alias(\"Erreur absolue moyenne\"),\n",
    "    F.avg(\"percent_error\").alias(\"% d'erreur moyen\"),\n",
    "    F.expr(\"percentile(percent_error, 0.5)\").alias(\"% d'erreur médian\")\n",
    ").show()"
   ],
   "id": "a3244e56d1a37fda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tempfile\n",
    "from minio import Minio\n",
    "\n",
    "def save_model_to_minio(model, model_name):\n",
    "    \"\"\"\n",
    "    Sauvegarde simplement un modèle PySpark dans le bucket ml_models de MinIO\n",
    "\n",
    "    Args:\n",
    "        model: Le modèle PySpark à sauvegarder\n",
    "        model_name (str): Nom du modèle (sera utilisé comme dossier dans le bucket)\n",
    "\n",
    "    Returns:\n",
    "        bool: True si la sauvegarde a réussi, False sinon\n",
    "    \"\"\"\n",
    "    # Configuration du client MinIO\n",
    "    minio_client = Minio(\n",
    "        endpoint=\"localhost:9000\",\n",
    "        access_key=\"minioadmin\",\n",
    "        secret_key=\"minioadmin\",\n",
    "        secure=False\n",
    "    )\n",
    "\n",
    "    bucket_name = \"models\"\n",
    "\n",
    "    try:\n",
    "        # Vérifier si le bucket existe, sinon le créer\n",
    "        if not minio_client.bucket_exists(bucket_name):\n",
    "            minio_client.make_bucket(bucket_name)\n",
    "            print(f\"Bucket '{bucket_name}' créé\")\n",
    "\n",
    "        # Créer un dossier temporaire pour sauvegarder le modèle\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            local_model_path = os.path.join(temp_dir, \"model\")\n",
    "\n",
    "            # Sauvegarder le modèle PySpark localement\n",
    "            model.save(local_model_path)\n",
    "\n",
    "            # Télécharger tous les fichiers du modèle vers MinIO\n",
    "            for root, dirs, files in os.walk(local_model_path):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    # Construire le chemin dans MinIO\n",
    "                    object_name = f\"{model_name}/{os.path.relpath(file_path, local_model_path)}\"\n",
    "\n",
    "                    # Uploader le fichier\n",
    "                    minio_client.fput_object(bucket_name, object_name, file_path)\n",
    "\n",
    "            print(f\"Modèle sauvegardé avec succès dans {bucket_name}/{model_name}\")\n",
    "            return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde du modèle: {e}\")\n",
    "        return False"
   ],
   "id": "19f09e79c22f24f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_model_to_minio(model, \"immobilier_value_predictor_model\")",
   "id": "d4dd5482783946a4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
